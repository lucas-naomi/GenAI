# Generative AI

## Overview

Generative AI refers to the technology that can analyze data to discover relationships and predictable sequences, allowing it to create new outputs such as text, images, and sounds. This is achieved through models that can represent and adapt to various forms of data.

**A Brief History of Artificial Intelligence** The history of AI dates back to 1950 when Alan Turing, often referred to as the father of AI, introduced the concept of machines capable of intelligent thought. Since then, AI has evolved significantly, with developments in neural networks and generative AI driven by advances in hardware and algorithms.

## Data Annotation
Annotated data, labeled manually by humans, is crucial for supervised learning. This process is time-consuming and expensive but necessary for training accurate models.
Take for instance that you want to develop a program to single out dogs in images. You must go through the rigorous process of feeding it with multiple labeled pictures of dogs and “non-dogs” to help the model learn what dogs look like. The program will then be able to compare new images with its existing repository to find out whether an image contains a dog in it.
Though the process is repetitive at the beginning, if enough annotated data is fed to the model, it will be able to learn how to identify or classify items in new data automatically without the need of labels. For the process to be successful, high quality annotated data is required. This is why most developers choose to use human resources for the annotation process.
The process might be automatized by using a machine to prepopulate the data, but a human touch and a human eye is preferred for review when the data is nuanced or sensitive. The higher the quality of annotated data fed to the training model, the higher the quality of the output. It is also important to note that most AI algorithms require regular updates to keep up with changes. Some may be updated as often as every day.

## Types of Annotation in Machine Learning

## Considering the following questions
- Who defines responsible use of generative AI, especially as cultural norms evolve and social engineering approaches vary across geographies? Who ensures compliance? What are the consequences for irresponsible use? 
- In the event something goes wrong, how can individuals take action?
- How do users give and remove consent (opt in or opt out)? What can be learned from the privacy debate?
- Will using generative AI help or hurt trust in your organization — and institutions overall?
- How can we ensure that content creators and owners keep control of their IP and are compensated fairly? What should new economic models look like? 
- Who will ensure proper functioning throughout the entire life cycle, and how will they do so? Do boards need an AI ethics lead, for example?

## Risks of Generative AI
- Lack of transparency. Generative AI and ChatGPT models are unpredictable, and not even the companies behind them always understand everything about how they work.
- Accuracy. Generative AI systems sometimes produce inaccurate and fabricated answers. Assess all outputs for accuracy, appropriateness and actual usefulness before relying on or publicly distributing information. 
- Bias. You need policies or controls in place to detect biased outputs and deal with them in a manner consistent with company policy and any relevant legal requirements.
- Intellectual property (IP) and copyright. There are currently no verifiable data governance and protection assurances regarding confidential enterprise information. Users should assume that any data or queries they enter into the ChatGPT and its competitors will become public information, and we advise enterprises to put in place controls to avoid inadvertently exposing IP. 
- Cybersecurity and fraud. Enterprises must prepare for malicious actors’ use of generative AI systems for cyber and fraud attacks, such as those that use deep fakes for social engineering of personnel, and ensure mitigating controls are put in place. Confer with your cyber-insurance provider to verify the degree to which your existing policy covers AI-related breaches.
- Sustainability. Generative AI uses significant amounts of electricity. Choose vendors that reduce power consumption and leverage high-quality renewable energy to mitigate the impact on your sustainability goals.
- 'Hallucinations' are outputs that are nonsensical or inaccurate but seem plausible. For instance, a lawyer once used a generative AI tool for research, only to find that it had produced entirely fictional cases. To mitigate such issues, developers implement guardrails—preventive measures that restrict the model's output. Continuous evaluation and tuning are essential to minimize inaccuracies.
